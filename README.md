# chinese-text-classification
### **1. 项目简介**

本项目旨在完成一个高效的中文文本分类任务，能够对不同主题的文本进行自动分类。

---

### **2. 数据来源**

- **数据集**：  
  本实验使用的数据集为THUCNews文本数据集，从中选取六个类别的新闻文章（“体育”、“财经”、“房产”、“家居”、“教育”、“科技”），每个类别包含5000条数据。
  
- **文件格式**：  
  数据存储为 `.txt` 文件，每行表示一条记录，格式为 `类别\t新闻内容`。
  

---

### **3. 中文文本分类思路**

#### **(1) 数据预处理**

- **分词与去停用词**：
  使用 `jieba` 对中文文本进行分词，并去除停用词以减少噪声。
- **特征提取**：
  使用 TF-IDF 提取文本特征，生成高维稀疏矩阵。
- **降维处理**：
  针对高维稀疏特征，采用 TruncatedSVD 进行降维，优化特征空间，提升模型性能。

#### **(2) 模型选择**

- **朴素贝叶斯**：
  直接使用未降维的 TF-IDF 特征矩阵，适配高维稀疏数据。
- **KNN** 和 **GBDT**：
  使用降维后的特征矩阵（TruncatedSVD），缓解高维稀疏数据对模型的影响。

#### **(3) 模型评估**

- **评价指标**：
  使用准确率（Accuracy）、宏平均 F1-Score（Macro F1）、加权平均 F1-Score（Weighted F1）等指标评估模型性能。
- **混淆矩阵**：
  绘制混淆矩阵热力图，直观展示分类结果。

---

### **4. 实验总结**

#### **(1) 模型性能对比**

- **GBDT** 表现最佳，准确率为 0.9583，宏平均和加权平均指标均最高，表明其在处理复杂数据模式时具有较强的泛化能力。
- **KNN** 准确率为 0.949，表现次优，尤其在经过 TruncatedSVD 降维后性能显著提升。
- **朴素贝叶斯** 准确率为 0.946，虽然稍逊于其他两种模型，但其简单高效，在很多情况下是一个不错的选择。

#### **(2) 数据降维的作用**

- **TruncatedSVD** 对 KNN 和 GBDT 的性能提升显著，尤其是在处理高维稀疏数据时，能够有效降低特征维度并去除噪声。

#### **(3) 思考与反思**

- **模型选择的权衡**：
  - GBDT 性能最优，但训练时间较长，适合对精度要求高的场景。
  - KNN 和朴素贝叶斯训练速度快，适合实时性要求高的任务。

#### **(4) 实验启示**

- 合理选择模型和降维方法对于提升分类性能至关重要。
- 数据预处理和特征工程是影响模型性能的关键步骤。
- 本实验不仅验证了不同模型在文本分类任务中的表现，还深入体现了数据降维和模型选择对最终结果的影响。

---

### **5. 总结**

本项目通过完整的中文文本分类流程，验证了朴素贝叶斯、KNN 和 GBDT 模型在多类别分类任务中的表现，并探索了 TruncatedSVD 在高维稀疏数据中的应用。在未来的实际应用中，应当综合考虑训练任务、数据规模、数据维度、训练时长等多方面因素来选择合适的模型进行训练。
